{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771b9ba7",
   "metadata": {},
   "source": [
    "## Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ac688",
   "metadata": {},
   "source": [
    "Аугментация данных - это методика создания дополнительных данных из уже имеющихся данных. Наиболее популярными способами аугментации изображений являются:\n",
    "\n",
    "* отображение по вертикали или горизонтали (flipping)\n",
    "* поворот изображения на определенный угол (rotation)\n",
    "* создание отступа (padding)\n",
    "* вырезание части изображения (cropping)\n",
    "* добавление шума (adding noise)\n",
    "* манипуляции с цветом (color jittering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8ce5f",
   "metadata": {},
   "source": [
    "Воспользуемся методом **RandomZoom**, который позволяет приближать случайные участки изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbea08c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 21:02:18.845648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential # импортируем пустую последовательную модель Sequential, на которую последовательно навешиваем слои \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, InputLayer, RandomZoom # импортируем слои Dense (полносвязный), Flatten (чтобы расплющить результаты, сделать их одномерным массивом; чтобы слои Dense смогли принять данные с свёрточных слоёв); слой Dropout позволяет избежать переобучения\n",
    "from keras.datasets import fashion_mnist # импортируем из модуля keras.datasets класс fashion_mnist (база данных изображений одежды)\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58416623",
   "metadata": {},
   "source": [
    "## Импортируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69820d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() # x_train, x_test: массив данных изображений в градациях серого uint8 с формой (размерность 28х28). y_train, y_test: массив меток uint8 (целые числа в диапазоне от 0 до 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06810a",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b88aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train.astype('float32') / 255 # приводим данные к вещественным числам и делим на 255, потому что нейросети удобнее работать со значениями от 0 до 1, а не от 0 до 255\n",
    "x_test_norm = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d4e954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
       "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
       "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
       "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
       "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
       "        0.50980395, 0.28235295, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
       "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
       "        0.34509805, 0.6745098 , 0.25882354],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
       "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
       "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
       "        0.76862746, 0.8980392 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
       "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
       "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
       "        0.9607843 , 0.6784314 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
       "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
       "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
       "        0.9529412 , 0.7921569 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
       "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
       "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
       "        0.77254903, 0.81960785, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
       "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
       "        0.46666667, 0.654902  , 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
       "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
       "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
       "        0.81960785, 0.36078432, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
       "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
       "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
       "        1.        , 0.3019608 , 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
       "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
       "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
       "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
       "        0.95686275, 0.62352943, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
       "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
       "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
       "        0.93333334, 0.84313726, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
       "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
       "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
       "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
       "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
       "        0.9098039 , 0.9647059 , 0.        ],\n",
       "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
       "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
       "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
       "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
       "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
       "        0.89411765, 0.88235295, 0.        ],\n",
       "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
       "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
       "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
       "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
       "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
       "        0.8784314 , 0.8980392 , 0.11372549],\n",
       "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
       "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
       "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
       "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
       "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
       "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
       "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
       "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
       "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
       "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
       "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
       "        0.8039216 , 0.80784315, 0.4509804 ],\n",
       "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
       "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
       "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
       "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
       "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
       "        0.69411767, 0.8235294 , 0.36078432],\n",
       "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
       "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
       "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
       "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
       "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
       "        0.84705883, 0.6666667 , 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
       "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
       "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
       "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
       "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6466a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_norm = np_utils.to_categorical(y_train, 10) # проводим one-hot кодирование для labels (y) для 10 классов (10 классов картинок в датасете), чтобы нейросеть предсказывала данные в правильном формате (на выходе у сети будет 10 нейронов)\n",
    "y_test_norm = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684021a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90798e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f319c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd94e5",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0794a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 21:08:52.486507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(x_train_norm.shape[1], x_train_norm.shape[2], 1))) # добавляем свёрточный слой Conv2D; количество фильтров - 32; kernel_size - размер фильтра - 3х3; добавляем нелинейную активацию (функцию) Relu, чтобы всю нейросеть нельзя было свернуть в один нейрон; в самый первый слой сети передаём параметр input_shape=(28, 28) - размерность данных, которые будут подаваться в нейросеть - берётся из x_train_norm.shape без первого показтеля (количество экземпляров)\n",
    "model.add(MaxPooling2D(pool_size=2)) # добавляем слой Pooling с параметром pool_size - размер фильтров слоя Pooling\n",
    "model.add(Dropout(0.25)) # слой Dropout служит для того, чтобы модель не переобучалась; его смысл в том, что каждую итерацию обучения он случайным образом выключает какие-то из нейронов; 0.25 - доля тех нейронов, которая будет на время выключаться из процесса обучения; это связано с тем, что если моедль окажется зависима от какого-то одного нейрона (переобучится на нём), то когда этот нейрон попадёт в те 25%, что мы задали, нейросети придётся обучать модель на других нейронах\n",
    "\n",
    "model.add(Flatten()) # преобразовываем данные в одномерный массив (одномерный вектор) для того, чтобы можно было работать со слоем Dense\n",
    "model.add(Dense(32, activation='relu')) # полносвязный слой Dense не может работать с двумерным массивом данных (ему нужен одномерный массив), поэтому приходится предобрабатывать данные с помощью слоя Flatten\n",
    "model.add(Dense(10, activation='sigmoid')) # последний выходной слой (тоже полносвязный), однако в нём количество нейронов будет равно количеству классов датафрейма (10); softmax - специальная активация, при которой выходные числа преобразовываются в формат процентов (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a5a71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # скомпилируем модель - зададим правила, по которым модель будет обучаться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc13e876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,386\n",
      "Trainable params: 201,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b450bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b169a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_float = x_train_norm.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8dc771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "362ab7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_float = x_train_float.reshape(-1, 1)\n",
    "x_train_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310e0a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47040000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60da04ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_float = x_test_norm.reshape(-1, 1)\n",
    "x_test_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f961c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a818cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1)\n",
      "x_test shape:  (10000, 28, 28, 1)\n",
      "y_train shape:  (60000, 1, 1, 1)\n",
      "y_test shape:  (10000, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_aug = x_train_float.reshape(-1, 28, 28, 1)\n",
    "x_test_aug = x_test_float.reshape(-1, 28, 28, 1)\n",
    "y_train_aug = np.reshape(y_train, (60000, 1, 1, 1))\n",
    "y_test_aug = np.reshape(y_test, (10000, 1, 1, 1))\n",
    "print(\"x_train shape: \", x_train_aug.shape)\n",
    "print(\"x_test shape: \", x_test_aug.shape)\n",
    "print(\"y_train shape: \", y_train_aug.shape)\n",
    "print(\"y_test shape: \", y_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1e7fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    shear_range = 0.3,# shear angle in counter-clockwise direction in degrees  \n",
    "    width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "    vertical_flip=True)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cd734d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ada5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 10\n",
    "#batch_size = 86\n",
    "\n",
    "#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            #patience=3, \n",
    "                                            #verbose=1, \n",
    "                                            #factor=0.5, \n",
    "                                            #min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b135eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit_generator(datagen.flow(x_train_aug, y_train, batch_size = batch_size),\n",
    "                              #epochs = epochs, validation_data = (x_test, y_test),\n",
    "                              #verbose = 2, steps_per_epoch = x_train.shape[0] // batch_size\n",
    "                              #, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6faead4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "datagen.fit(x_train_aug, y_train_aug, epochs=10) # обучаем модель; функция ошибки (loss) должна уменьшаться, точность (accuracy) увеличиваться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19029c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf665ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
