{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272253db",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "1. Использовать датасет Fashion-MNIST для обучения нейросети.\n",
    "2. Сделать снимок какого-нибудь элемента одежды и предсказать его класс с помощью нейронной сети CNN.\n",
    "3. Добавить аугментацию данных для увеличения датасета. Сравнить качество распознавания как на датасете, так и на собственных изображениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e06db26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential # импортируем пустую последовательную модель Sequential, на которую последовательно навешиваем слои \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, InputLayer # импортируем слои Dense (полносвязный), Flatten (чтобы расплющить результаты, сделать их одномерным массивом; чтобы слои Dense смогли принять данные с свёрточных слоёв); слой Dropout позволяет избежать переобучения\n",
    "from keras.datasets import fashion_mnist # импортируем из модуля keras.datasets класс fashion_mnist (база данных изображений одежды)\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d22f8",
   "metadata": {},
   "source": [
    "## Импортируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "944218ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() # x_train, x_test: массив данных изображений в градациях серого uint8 с формой (размерность 28х28). y_train, y_test: массив меток uint8 (целые числа в диапазоне от 0 до 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f38fd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "x_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# выводим размерности данных\n",
    "print(f'x_train.shape: {x_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'x_test.shape: {x_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e1f28",
   "metadata": {},
   "source": [
    "## Проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfb66f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NUMBER = 0 # выбираем значение от 0 до 60 000 по колиечтсву значений в нашем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aaf034cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKLklEQVR4nO3duU+VWx/F8X0EJwbBiQBqRKNEGoNxHhONGu0MJtgaYmPvf2Ch0drO0loL4xR7MEqMgYJGHFGDqEiYBTy3et/KZ/3enCe8rpP7/ZR3ZcMZWPdJ/GXvXSgWiwmAnyV/+wUA+DPKCZiinIApygmYopyAqUoVFgoF/ikXWGTFYrHwp//OkxMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVPyaEz8/xUKfzwl8b/yXjxVW1sr8yNHjmRmjx49yvW7o/dWUVGRmc3Pz+f63XlFr10p9TvjyQmYopyAKcoJmKKcgCnKCZiinIApygmYYs5pZskS/f/LhYUFmW/btk3mly5dkvn09HRmNjk5KdfOzMzI/Pnz5zLPM8uM5pDR5xqtz/Pa1PxW4ckJmKKcgCnKCZiinIApygmYopyAKcoJmGLOaSaaiUVzzhMnTsj85MmTMh8aGsrMli9fLtdWVVXJ/NSpUzK/fft2ZjY8PCzXRnsmo88tUlNTk5n9/v1brp2amirpd/LkBExRTsAU5QRMUU7AFOUETFFOwBTlBEwx5zTz69evXOv37t0r85aWFpmrOWu0J/LJkycy37Vrl8xv3LiRmfX29sq1/f39Mh8YGJD5vn37ZK4+1+7ubrm2p6dH5ll4cgKmKCdginICpignYIpyAqYoJ2CKUcpfoI5hjLY+Rduu9uzZI/Px8XGZV1dXZ2atra1ybZS/ePFC5q9fv87M1JatlFI6ePCgzDs6OmQ+Nzcnc/Xao+NGZ2dnZZ6FJydginICpignYIpyAqYoJ2CKcgKmKCdgqqDmaoVCQQ/d/qWi6+LyiOacz549k3m0JSyi3lt0DV7e7W7qCsHo+MmXL1/KXM1QU4rf25kzZzKzrVu3yrUbNmyQebFY/OOHzpMTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMMV+zhJEs8jFNDo6KvOmpiaZT09Py1xd81dZqf9coj2Xao6ZUkorV67MzKI559GjR2V+6NAhmUfHfjY0NGRmjx8/lmtLxZMTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMMWcs8xUVVXJPJrXRfnU1FRmNjY2Jtd+//5d5tFe02BvsVwbva/oc1tYWJC5mrNu2rRJri0VT07AFOUETFFOwBTlBExRTsAU5QRMUU7AFHPOEuSduamZWrQnsrm5WebRXZBRrvZzRufSqhlpSinV19fLXM1JoznlsmXLZB7dS1pXVyfzvr6+zCz6zqI7U7Pw5ARMUU7AFOUETFFOwBTlBExRTsAUo5QSREdjVlRUyFyNUi5cuCDXNjY2ynxkZETm6vjJlPTWqOrqark22joVjWLUGGdubk6ujY7tjN732rVrZX7r1q3MrL29Xa6NXlsWnpyAKcoJmKKcgCnKCZiinIApygmYopyAqUJwHOHfu+vOWDS3mp+fL/ln79+/X+YPHjyQeXTFX54ZbG1trVwbXfEXHZ25dOnSkrKU4hlsdHViRL23mzdvyrV37tyRebFY/OMeRJ6cgCnKCZiinIApygmYopyAKcoJmKKcgKlF3c+pjpCM5m3R8ZLR8ZRq/5/as/i/yDPHjDx8+FDmk5OTMo/mnNERkmruHe0Vjb7TFStWyDzas5lnbfSdR699586dmVl0NWKpeHICpignYIpyAqYoJ2CKcgKmKCdginICpnLNOfPsDVzMWeFiO3bsmMzPnz8v88OHD2dm0TV60Z7IaI4Z7UVV31n02qK/B3UubUp6DhqdFRy9tkj0uU1MTGRmHR0dcu39+/dLek08OQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTtufWrlmzRubNzc0y3759e8lro7lVa2urzGdnZ2Wu9qpG+xKjeyY/f/4s8+j8VzXvi+6wjO7frKqqknl3d3dmVlNTI9dGs+doP2e0J1N9bsPDw3JtW1ubzDm3FigzlBMwRTkBU5QTMEU5AVOUEzCVa5Ry4MAB+cOvXr2ama1fv16ura+vl7na2pSS3r708+dPuTbazhaNBKKRgjrWMzracmBgQOadnZ0y7+3tlbm65m/16tVybUtLi8wjb968ycyi6wfHx8dlHm0pi0ZUapSzatUquTb6e2GUApQZygmYopyAKcoJmKKcgCnKCZiinIApOeesrKyUc86enh75w5uamjKzaE4Z5XmOQoyOcIxmjXnV1dVlZuvWrZNrL168KPPTp0/L/PLlyzJXW85mZmbk2rdv38pczTFT0tv88m5Xi7bKRXNUtT7ajrZ582aZM+cEygzlBExRTsAU5QRMUU7AFOUETFFOwJScc3Z1dck55/Xr1+UPHxwczMyiow6jPLpOTolmXmoOmVJKHz9+lHl0PKXay6qOzUwppcbGRpmfO3dO5uqavZT0nszoO9m9e3euXL33aI4ZfW7RFX8RtQc3+nuK9j1/+PCBOSdQTignYIpyAqYoJ2CKcgKmKCdginICpipV+PXrV7k4mvepPXLRNXnRz45mbmquFZ0z+uPHD5m/f/9e5tFrU/tFoz2T0Zm69+7dk3l/f7/M1ZwzupYxmkVG5wWr6w+j9x3tqYxmkdF6NeeMZqjRlZFZeHICpignYIpyAqYoJ2CKcgKmKCdgSo5SPn36JBer7WYppTQ0NJSZVVdXy7XREZHRP8t/+/YtMxsZGZFrKyvlxxJuV4v+2V5t24qOaIy2Rqn3nVJKbW1tMp+cnMzMovHW6OiozKPPTb12NWZJKR61ROujKwDVVr2xsTG5tr29XeZZeHICpignYIpyAqYoJ2CKcgKmKCdginICpuRA79WrV3Lx3bt3Zd7V1ZWZRcdHRtfFRVur1LataA4ZzbyiLULRFYNqu1x09WE0W46uRvzy5UvJPz96bdF8OM93lnc7Wp7tainpOeqWLVvk2uHhYZln4ckJmKKcgCnKCZiinIApygmYopyAKcoJmJJXABYKBT1UC5w9ezYzu3Llilzb0NAg82jfopprRfO6aE4ZzTmjeZ/6+eoIxpTiOWc0w41y9d6itdFrj6j1pc4K/yP6zqKjMdV+zr6+Prm2s7NT5sVikSsAgXJCOQFTlBMwRTkBU5QTMEU5AVOUEzAl55wVFRVyqBbNhvI4fvy4zK9duyZzNSetq6uTa6OzYaM5aDTnjOasSnQtYzQHjc4iVt/pxMSEXBt9LhH12qP9ltE+1ug7ffr0qcwHBgYys+7ubrk2wpwTKDOUEzBFOQFTlBMwRTkBU5QTMEU5AVOLup/T1Y4dO2Se927QjRs3yvzdu3eZWTTPGxwclDnKD3NOoMxQTsAU5QRMUU7AFOUETFFOwNS/cpQCOGGUApQZygmYopyAKcoJmKKcgCnKCZiinIApygmYopyAKcoJmKKcgCnKCZiinIApygmYopyAKbmfE8Dfw5MTMEU5AVOUEzBFOQFTlBMwRTkBU/8A0u/ZrlPqEFgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[SAMPLE_NUMBER], cmap='gray') # используем функцию imshow для отображения изображения\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53f6934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это изображение класса: 9\n"
     ]
    }
   ],
   "source": [
    "print(f'Это изображение класса: {y_train[SAMPLE_NUMBER]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dbae7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_classes = [ # задаём название для каждого значения класса\n",
    "  'T-shirt/top',\n",
    "  'Trouser',\n",
    "  'Pullover',\n",
    "  'Dress',\n",
    "  'Coat',\n",
    "  'Sandal',\n",
    "  'Shirt',\n",
    "  'Sneaker',\n",
    "  'Bag',\n",
    "  'Ankle boot'\n",
    "]\n",
    "\n",
    "def class_name(ix):\n",
    "  return fashion_mnist_classes[np.array(ix).flatten()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28fe9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это изображение класса: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "print(f'Изображение:')\n",
    "plt.imshow(x_train[SAMPLE_NUMBER], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f'Это изображение класса: {class_name(y_train[SAMPLE_NUMBER])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753a836",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c33cb532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0] # отображаем массив данных, который хранится в значении \"0\"; из результатов видно, что значение каждого элемента (пикселя) находится в диапазоне от 0 до 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551d85a",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92fe77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train.astype('float32') / 255 # приводим данные к вещественным числам и делим на 255, потому что нейросети удобнее работать со значениями от 0 до 1, а не от 0 до 255\n",
    "x_test_norm = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57de22da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
       "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
       "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
       "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
       "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
       "        0.50980395, 0.28235295, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
       "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
       "        0.34509805, 0.6745098 , 0.25882354],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
       "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
       "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
       "        0.76862746, 0.8980392 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
       "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
       "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
       "        0.9607843 , 0.6784314 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
       "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
       "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
       "        0.9529412 , 0.7921569 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
       "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
       "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
       "        0.77254903, 0.81960785, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
       "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
       "        0.46666667, 0.654902  , 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
       "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
       "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
       "        0.81960785, 0.36078432, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
       "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
       "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
       "        1.        , 0.3019608 , 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
       "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
       "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
       "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
       "        0.95686275, 0.62352943, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
       "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
       "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
       "        0.93333334, 0.84313726, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
       "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
       "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
       "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
       "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
       "        0.9098039 , 0.9647059 , 0.        ],\n",
       "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
       "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
       "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
       "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
       "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
       "        0.89411765, 0.88235295, 0.        ],\n",
       "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
       "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
       "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
       "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
       "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
       "        0.8784314 , 0.8980392 , 0.11372549],\n",
       "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
       "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
       "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
       "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
       "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
       "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
       "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
       "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
       "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
       "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
       "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
       "        0.8039216 , 0.80784315, 0.4509804 ],\n",
       "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
       "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
       "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
       "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
       "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
       "        0.69411767, 0.8235294 , 0.36078432],\n",
       "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
       "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
       "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
       "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
       "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
       "        0.84705883, 0.6666667 , 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
       "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
       "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
       "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
       "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0b8a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_norm = np_utils.to_categorical(y_train, 10) # проводим one-hot кодирование для labels (y) для 10 классов (10 классов картинок в датасете), чтобы нейросеть предсказывала данные в правильном формате (на выходе у сети будет 10 нейронов)\n",
    "y_test_norm = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3cd2191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afdd9b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad279890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb5fbb",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9293aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(x_train_norm.shape[1], x_train_norm.shape[2], 1))) # добавляем свёрточный слой Conv2D; количество фильтров - 32; kernel_size - размер фильтра - 3х3; добавляем нелинейную активацию (функцию) Relu, чтобы всю нейросеть нельзя было свернуть в один нейрон; в самый первый слой сети передаём параметр input_shape=(28, 28) - размерность данных, которые будут подаваться в нейросеть - берётся из x_train_norm.shape без первого показтеля (количество экземпляров)\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # добавляем слой Pooling с параметром pool_size - размер фильтров слоя Pooling\n",
    "model.add(Dropout(0.25)) # слой Dropout служит для того, чтобы модель не переобучалась; его смысл в том, что каждую итерацию обучения он случайным образом выключает какие-то из нейронов; 0.25 - доля тех нейронов, которая будет на время выключаться из процесса обучения; это связано с тем, что если моедль окажется зависима от какого-то одного нейрона (переобучится на нём), то когда этот нейрон попадёт в те 25%, что мы задали, нейросети придётся обучать модель на других нейронах\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) # преобразовываем данные в одномерный массив (одномерный вектор) для того, чтобы можно было работать со слоем Dense\n",
    "model.add(Dense(512, activation='relu')) # полносвязный слой Dense не может работать с двумерным массивом данных (ему нужен одномерный массив), поэтому приходится предобрабатывать данные с помощью слоя Flatten\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # последний выходной слой (тоже полносвязный), однако в нём количество нейронов будет равно количеству классов датафрейма (10); softmax - специальная активация, при которой выходные числа преобразовываются в формат процентов (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "848e39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # скомпилируем модель - зададим правила, по которым модель будет обучаться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c9cecda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,929,706\n",
      "Trainable params: 1,929,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "68fc6e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 169s 449ms/step - loss: 0.4748 - accuracy: 0.8244 - val_loss: 0.3355 - val_accuracy: 0.8752\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 162s 432ms/step - loss: 0.3034 - accuracy: 0.8892 - val_loss: 0.2566 - val_accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 156s 417ms/step - loss: 0.2533 - accuracy: 0.9074 - val_loss: 0.2290 - val_accuracy: 0.9173\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 148s 396ms/step - loss: 0.2230 - accuracy: 0.9180 - val_loss: 0.2156 - val_accuracy: 0.9207\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 155s 413ms/step - loss: 0.2023 - accuracy: 0.9256 - val_loss: 0.2229 - val_accuracy: 0.9207\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 159s 424ms/step - loss: 0.1809 - accuracy: 0.9332 - val_loss: 0.2084 - val_accuracy: 0.9283\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 163s 436ms/step - loss: 0.1659 - accuracy: 0.9387 - val_loss: 0.2074 - val_accuracy: 0.9257\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 166s 443ms/step - loss: 0.1476 - accuracy: 0.9450 - val_loss: 0.2021 - val_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 198s 528ms/step - loss: 0.1356 - accuracy: 0.9499 - val_loss: 0.1977 - val_accuracy: 0.9314\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 193s 515ms/step - loss: 0.1219 - accuracy: 0.9538 - val_loss: 0.2058 - val_accuracy: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefccef09d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_norm, y_train_norm, epochs=10, batch_size=128, validation_split=0.2) # обучаем модель; параметр batch_size - количество изображений (экземпляров) пройдёт прежде чем обновить свои веса; validation_split - разбивает существующий X_train и Y_train на тренировочные и тестовые данные, 0.2 означает, что 20% уходит в тестовые данные, по которым нейросеть будет оцениваться; функция ошибки (loss) должна уменьшаться, точность (accuracy) увеличиваться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1994473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 34ms/step - loss: 0.2299 - accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22989089787006378, 0.9258999824523926]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_norm, y_test_norm) # проверяем точность на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e53ba7",
   "metadata": {},
   "source": [
    "## Проверка работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eecf1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(url):\n",
    "  response = requests.get(url)\n",
    "  img = Image.open(BytesIO(response.content))\n",
    "  width, height = img.size\n",
    "  square_side = min(width, height)\n",
    "  img = img.crop((\n",
    "    np.ceil((width - square_side) / 2),\n",
    "    np.ceil((height - square_side) / 2),\n",
    "    np.ceil((width + square_side) / 2),\n",
    "    np.ceil((height + square_side) / 2)\n",
    "  ))\n",
    "\n",
    "  img.thumbnail((28, 28))\n",
    "  np_array = np.array(img) / 255\n",
    "\n",
    "  return np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "17f610f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fefc9a43fd0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(resize_image('https://piterdm.ru/images/statyu/chernye_futbolki_dlya_sublimacii.jpg')) # загружаем фотографию\n",
    "# https://piterdm.ru/images/statyu/chernye_futbolki_dlya_sublimacii.jpg\n",
    "# https://i.imgur.com/BNzjEyH.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "639d3ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_48_input'), name='conv2d_48_input', description=\"created by layer 'conv2d_48_input'\"), but it was called on an input with incompatible shape (None, 28, 28, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_22' (type Sequential).\n    \n    Input 0 of layer \"conv2d_48\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential_22' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_name(np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://piterdm.ru/images/statyu/chernye_futbolki_dlya_sublimacii.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/hy/pfmkjt294bl40vdb0nfc_y4c0000gn/T/__autograph_generated_filejeqr28md.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_22' (type Sequential).\n    \n    Input 0 of layer \"conv2d_48\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential_22' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "class_name(np.argmax(model.predict(np.array([resize_image('https://piterdm.ru/images/statyu/chernye_futbolki_dlya_sublimacii.jpg')]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02862d8a",
   "metadata": {},
   "source": [
    "## Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f00e4",
   "metadata": {},
   "source": [
    "Аугментация данных - это методика создания дополнительных данных из уже имеющихся данных. Наиболее популярными способами аугментации изображений являются:\n",
    "\n",
    "* отображение по вертикали или горизонтали (flipping)\n",
    "* поворот изображения на определенный угол (rotation)\n",
    "* создание отступа (padding)\n",
    "* вырезание части изображения (cropping)\n",
    "* добавление шума (adding noise)\n",
    "* манипуляции с цветом (color jittering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137f19d",
   "metadata": {},
   "source": [
    "Воспользуемся методом **RandomZoom**, который позволяет приближать случайные участки изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "100f07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_augmentation = tf.keras.Sequential([\n",
    "  #tf.keras.layers.experimental.preprocessing.RandomZoom((-0.05,0.05))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fc2d0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.experimental.preprocessing.RandomZoom((-0.05,0.05))])\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(x_train_norm.shape[1], x_train_norm.shape[2], 1))) # добавляем свёрточный слой Conv2D; количество фильтров - 32; kernel_size - размер фильтра - 3х3; добавляем нелинейную активацию (функцию) Relu, чтобы всю нейросеть нельзя было свернуть в один нейрон; в самый первый слой сети передаём параметр input_shape=(28, 28) - размерность данных, которые будут подаваться в нейросеть - берётся из x_train_norm.shape без первого показтеля (количество экземпляров)\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # добавляем слой Pooling с параметром pool_size - размер фильтров слоя Pooling\n",
    "model.add(Dropout(0.25)) # слой Dropout служит для того, чтобы модель не переобучалась; его смысл в том, что каждую итерацию обучения он случайным образом выключает какие-то из нейронов; 0.25 - доля тех нейронов, которая будет на время выключаться из процесса обучения; это связано с тем, что если моедль окажется зависима от какого-то одного нейрона (переобучится на нём), то когда этот нейрон попадёт в те 25%, что мы задали, нейросети придётся обучать модель на других нейронах\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) # преобразовываем данные в одномерный массив (одномерный вектор) для того, чтобы можно было работать со слоем Dense\n",
    "model.add(Dense(512, activation='relu')) # полносвязный слой Dense не может работать с двумерным массивом данных (ему нужен одномерный массив), поэтому приходится предобрабатывать данные с помощью слоя Flatten\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # последний выходной слой (тоже полносвязный), однако в нём количество нейронов будет равно количеству классов датафрейма (10); softmax - специальная активация, при которой выходные числа преобразовываются в формат процентов (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5a689596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # скомпилируем модель - зададим правила, по которым модель будет обучаться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "75d7978e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [174]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:3292\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3263\u001b[0m \n\u001b[1;32m   3264\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3289\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3290\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 3292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3296\u001b[0m     )\n\u001b[1;32m   3297\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   3298\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3299\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[1;32m   3305\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "efd3f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_31' (type Sequential).\n    \n    Input 0 of layer \"conv2d_76\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (128, 28, 28)\n    \n    Call arguments received by layer 'sequential_31' (type Sequential):\n      • inputs=tf.Tensor(shape=(128, 28, 28), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [175]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/hy/pfmkjt294bl40vdb0nfc_y4c0000gn/T/__autograph_generated_filegbfe6h6d.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrey/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_31' (type Sequential).\n    \n    Input 0 of layer \"conv2d_76\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (128, 28, 28)\n    \n    Call arguments received by layer 'sequential_31' (type Sequential):\n      • inputs=tf.Tensor(shape=(128, 28, 28), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_norm, y_train_norm, epochs=10, batch_size=128, validation_split=0.2) # обучаем модель; параметр batch_size - количество изображений (экземпляров) пройдёт прежде чем обновить свои веса; validation_split - разбивает существующий X_train и Y_train на тренировочные и тестовые данные, 0.2 означает, что 20% уходит в тестовые данные, по которым нейросеть будет оцениваться; функция ошибки (loss) должна уменьшаться, точность (accuracy) увеличиваться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1dc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
